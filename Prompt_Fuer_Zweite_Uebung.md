<!-- markdownlint-disable -->

Wir haben bald einen Test im Fach Web-Medien-Computing (WMC) - In diesem Fach haben wir als Testumfang die Clean-Architecture (wie im Directory @CleanArchitecture_Template zu finden ist)

Die zu lernenden Designpattern und Architekturen / Frameworks sind exakt die, die auch in diesem Template implementiert sind, keine anderen. Beim Test dÃ¼rfen und werden wir auch exakt dieses Template, als UnterstÃ¼tzung, verwenden, Ã¤ndere absolut NICHTS daran.

Ultrathink fÃ¼r diese gesamte, folgende Aufgabenstellung.

Deine Aufgabe wird jetzt sein mir ein Ãœbungsbeispiel (eine Art LÃ¼ckentext) in dem Verzeichnis @CleanArchitecture_Uebung_01 zu erstellen, das als Analogie der Angabe, die wir beim Test bekommen werden, dienen soll.
Beim Test werden wir natÃ¼rlich nicht Sensors/Measurements implementieren mÃ¼ssen, sondern irgendeine andere Software-Aufgabenstellung (mit drei EntitÃ¤ten - dies wissen wir schon) sei bitte kreativ und denk dir eine Aufgabenstellung aus, die alles abdeckt, aber mich nicht zu sehr Ã¼berwÃ¤ltigt.
Die KomplexitÃ¤t wird Ã¤hnlich der KomplexitÃ¤t des Templates sein.
Wir werden Validierungen auf den drei Ebenen zu implementieren haben -
Fluent Validation bei einer EntitÃ¤t (Validierung), einmal Domain Validation, einmal Application Validation.
Wir werden eine GET ALL, eine GET BY ID, CREATE, eine DELETE und eine UPDATE Methode (Controller) implementieren mÃ¼ssen und fÃ¼r jeden Flow (wie im Template zu sehen Command, CommandHandler, CommandValidator oder das selbe mit Queries und deren Handler und Validator)

(Unittests werden wir auch haben, die uns unterstÃ¼tzen sollten - Auch diese bitte kreieren)

Wie erwÃ¤hnt soll die Vorlage ein LÃ¼ckentext sein (implementiere "throw not implemented exceptions" in Controller oder nur die Ordner bei Features z.B.)

und erzeuge eine README als Angabe in @CleanArchitecture_Uebung_01 in der du erklÃ¤rst welche Validations ich implementieren soll und welche Responses etc.

---

Beachte folge Notizen meiner Kollegin:

FÃ¼r den Test werden diese Dinge zu machen sein:
Wir mÃ¼ssen Commands mit Validator und Handler etc. selber machen kÃ¶nnen.
Validations auf Domain- und Application-Ebene
Controller sind zu implementieren
FÃ¼r Domain-Ebene und API-Ebene wurden Tests erstellt - Methodennamen abgleichen
Man muss bei der Dependency Injection den Service registrieren - also wie ISensorUniquenessChecker

In der Infrastruktur wird DataSeeder und Repositories fertig sein. - mÃ¼sste normalerweise neu angelegt werden, aber wÃ¤re beim Test zu lang.
Repository-Methoden fÃ¼r spezielle Abfragen mÃ¼ssen wir hinzufÃ¼gen - z. B. erste 100 Messungen, die mit x anfangen.

Bei der API mÃ¼ssen die entsprechenden Controller hinzugefÃ¼gt werden. 

Ich acker mich so durch, dass ich zuerst die Domain und Infrastruktur aufbaue, bevor ich mich an die API mache. Ich finde, wenn man UniquenessChecker und Validation etc. spÃ¤ter erst macht, hat man ja Ã¼berhaupt keinen Ãœberblick, wo dann nachtrÃ¤glich nochmal was ergÃ¤nzt werden muss.

ğŸ¤“ğŸ¤œğŸ»ğŸ¤›ğŸ»ğŸ¤–

